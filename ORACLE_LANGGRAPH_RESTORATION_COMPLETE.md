# Horror Oracle LangChain Backend Integration - RESTORATION COMPLETE

## Overview
Successfully restored the Horror Oracle LangGraph backend integration. The quiz system now uses adaptive AI-driven question generation instead of static questions.

## Changes Made

### 1. Backend Routes (horror.py)
Updated Flask routes to use camelCase `userId` for JavaScript convention consistency:

**`/api/start_quiz` (Line 1142-1166)**
```python
@app.route("/api/start_quiz", methods=["POST"])
def api_start_quiz():
    data = request.get_json(silent=True) or {}
    user_id = data.get("userId", "guest")  # âœ… Changed from "user_id" to "userId"
    
    quiz = start_first_quiz(user_id)
    return jsonify(quiz)
```

**`/api/submit_answers` (Line 1169-1177)**
```python
@app.route("/api/submit_answers", methods=["POST"])
def api_submit_answers():
    data = request.get_json(silent=True) or {}
    user_id = data.get("userId", "guest")  # âœ… Changed from "user_id" to "userId"
    quiz = data.get("quiz", {})
    answers = data.get("answers", {})
    
    result = evaluate_and_progress(user_id, quiz, answers)
    return jsonify(result)
```

### 2. Frontend (script-js-combined.js)
Updated JavaScript to send `userId` in camelCase:

**startOracleQuiz() (Line 1740-1743)**
```javascript
body: JSON.stringify({ 
    userId: userId,  // âœ… Changed from user_id to userId
    force_new: true
})
```

**Submit Answers (Line 1908-1912)**
```javascript
body: JSON.stringify({
    userId: oracleState.userId,  // âœ… Changed from user_id to userId
    quiz: currentQuiz.oracleData,
    answers: answersDict
})
```

## LangGraph Chain Verification

### âœ… BuilderNode Uses LangGraph LLM
**File:** `oracle_engine/builder_node.py`

The BuilderNode generates NEW questions every time using:
- **LangChain Components:** ChatOpenAI, ChatPromptTemplate, JsonOutputParser
- **Temperature:** 0.8 (high for creative variety)
- **No Caching:** Each quiz generates fresh questions
- **Fallback:** Direct OpenAI API if LangChain fails
- **Last Resort:** Randomized static questions from 100+ question pool

**Key Methods:**
```python
# Line 46-50: LangChain LLM Initialization
self.llm = ChatOpenAI(
    model=Config.LLM_MODEL,
    temperature=0.8,  # Higher temperature for creative questions
    api_key=Config.OPENAI_API_KEY
)

# Line 121-136: LangChain Chain Execution
chat_prompt = ChatPromptTemplate.from_messages([...])
parser = JsonOutputParser()
chain = chat_prompt | self.llm | parser
result = chain.invoke({theme, difficulty, tone})
```

### âœ… Full LangGraph Pipeline Active

**File:** `oracle_engine/main.py`

#### start_first_quiz() - Initial Quiz Generation
**Chain Flow:** Builder â†’ Profile â†’ Lore â†’ Fear Meter

1. **BuilderNode.generate_quiz()** - Generates 5 NEW questions via LLM
2. **ProfileNode.get_profile()** - Loads/creates user profile
3. **LoreWhispererNode.generate_lore()** - Creates atmospheric intro
4. **FearMeterNode.translate_to_oracle_state()** - Initializes emotional state

#### evaluate_and_progress() - Answer Evaluation
**Chain Flow:** Evaluator â†’ Reactor â†’ Fear Meter â†’ Reward â†’ Profile â†’ Recommender â†’ Lore

1. **EvaluatorNode.evaluate_answers()** - Grades player performance
2. **FearMeterNode.translate_to_oracle_state()** - Updates Oracle emotional response
3. **RewardNode.generate_rewards()** - Awards based on performance
4. **ProfileNode.update_profile()** - Saves player progress
5. **RecommenderNode.recommend_movies()** - Suggests horror movies
6. **LoreWhispererNode.whisper_between_chambers()** - Transitions to next quiz

## API Response Structure

### /api/start_quiz Response
```json
{
  "user_id": "string",
  "room": "Chamber of Intermediate",
  "intro": "The air grows cold...",
  "questions": [
    {
      "question": "string",
      "choices": ["A", "B", "C", "D"],
      "correct_answer": "A",
      "difficulty": 0.5,
      "tone": "creepy",
      "theme": "general_horror"
    }
  ],
  "theme": "general_horror",
  "difficulty": "intermediate",
  "tone": "creepy",
  "lore": { "intro": "...", "hint": "..." },
  "oracle_state": {
    "tone": "neutral",
    "emotion": "indifferent",
    "intensity": 0.5
  },
  "player_profile": { "bravery": 50, "fear_level": 50 }
}
```

### /api/submit_answers Response
```json
{
  "user_id": "string",
  "score": 4,
  "out_of": 5,
  "accuracy": 0.8,
  "percentage": 80.0,
  "evaluation": {
    "grade": "A",
    "verdict": "Excellent!",
    "detailed_feedback": [...],
    "oracle_reaction": "Impressive...",
    "unlocked_lore": {...}
  },
  "oracle_state": {
    "tone": "pleased",
    "emotion": "impressed",
    "intensity": 0.8,
    "next_tone": "encouraging",
    "atmospheric_message": "...",
    "behavior": {...},
    "narrative": {...}
  },
  "rewards": {...},
  "player_profile": {...},
  "recommendations": [...],
  "lore": {...},
  "next_action": "continue",
  "next_difficulty": "advanced"
}
```

## How It Works

### 1. User Clicks "Face Your Nightmares"
- Frontend calls `startOracleQuiz()`
- Fetches `/api/start_quiz` with `userId`

### 2. Backend Generates Quiz
- `start_first_quiz()` runs the Builder â†’ Profile â†’ Lore â†’ Fear Meter chain
- **BuilderNode calls LangChain LLM** to generate 5 NEW questions
- Returns quiz with atmospheric intro and Oracle state

### 3. Frontend Displays Quiz
- `displayOracleQuiz()` renders questions dynamically
- Shows `quiz.questions[i].question` and `quiz.questions[i].choices`
- Player selects answers

### 4. User Submits Answers
- Frontend calls `/api/submit_answers` with `userId`, `quiz`, and `answers`

### 5. Backend Evaluates Performance
- `evaluate_and_progress()` runs the full 7-node chain
- Evaluator grades answers
- Fear Meter adjusts Oracle's emotional state
- Profile updates player stats
- Recommender suggests horror movies based on performance
- Lore Whisperer generates transition text

### 6. Frontend Shows Results
- Displays score, Oracle reaction, and atmospheric messages
- Shows movie recommendations
- Updates player's fear level and profile

## Key Features

âœ… **Dynamic Question Generation** - LLM generates NEW questions every time (no repeats)  
âœ… **Adaptive Difficulty** - Adjusts based on player performance  
âœ… **Emotional Oracle** - Reacts to player answers with personality  
âœ… **Movie Recommendations** - Suggests horror films based on quiz theme and performance  
âœ… **Atmospheric Storytelling** - Lore Whisperer creates immersive transitions  
âœ… **Player Profiling** - Tracks bravery, lore knowledge, fear level  
âœ… **Reward System** - Unlocks content based on performance  

## Testing Instructions

### 1. Start Backend
```bash
python horror.py
```

### 2. Open Frontend
```
http://localhost:5000/index.html
```

### 3. Start Quiz
- Click "Face Your Nightmares" button
- Quiz should generate 5 NEW horror movie questions via LangChain
- Answer questions and submit

### 4. Verify LangGraph Chain
Check terminal for logs:
```
[ORACLE ENGINE] Starting quiz for user: guest
[1/4] Loading user profile...
[2/4] Generating quiz questions...
[BUILDER NODE] Generating NEW questions (no cache)
[BUILDER NODE] Calling LLM via LangChain to generate fresh questions...
[BUILDER NODE] Generated 5 NEW questions successfully via LangChain
[3/4] Whispering lore...
[4/4] Calibrating fear meter...
[OK] Quiz generated | Theme: general_horror | Difficulty: intermediate
```

### 5. Submit Answers
After answering, check terminal for evaluation logs:
```
[ORACLE ENGINE] Evaluating answers for user: guest
[1/7] Evaluating answers...
[2/7] Oracle reacts to performance...
[3/7] Generating rewards...
[4/7] Updating player profile...
[5/7] Generating movie recommendations...
[6/7] Whispering transition lore...
[7/7] Compiling final state...
[OK] Full chain complete | Next: continue
```

## Dependencies Required

Make sure these are installed:
```bash
pip install langchain langchain-openai openai flask flask-cors python-dotenv pinecone-client
```

## Environment Variables

Create `.env` file with:
```
OPENAI_API_KEY=sk-...
PINECONE_API_KEY=...
TMDB_API_KEY=...
OMDB_API_KEY=...
```

## Restoration Status

âœ… **Backend Integration** - Complete  
âœ… **Frontend Integration** - Complete  
âœ… **LangGraph Chain** - Verified  
âœ… **BuilderNode LLM** - Verified  
âœ… **Evaluator Chain** - Verified  
âœ… **Parameter Naming** - Updated to camelCase  
âœ… **No Linter Errors** - Verified  

## Summary

The Horror Oracle now uses a **complete LangGraph backend** with:
- ðŸ§  **AI-Driven Questions** - LangChain LLM generates fresh questions every quiz
- ðŸ“Š **7-Node Chain** - Builder â†’ Evaluator â†’ Fear Meter â†’ Reward â†’ Profile â†’ Recommender â†’ Lore
- ðŸŽ­ **Emotional Oracle** - Adapts personality based on player performance
- ðŸŽ¬ **Movie Recommendations** - Context-aware horror film suggestions
- ðŸ“ˆ **Player Progression** - Adaptive difficulty and profile tracking

**The integration is COMPLETE and READY!** ðŸ©¸

